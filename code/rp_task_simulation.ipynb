{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f23ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#*****************************************************************************************************\n",
    "# Fix settings concerning the ansatz, optimisation and backend\n",
    "#*****************************************************************************************************\n",
    "from time import time \n",
    "import pickle \n",
    "import numpy as np\n",
    "\n",
    "from discopy import Ty, Id, Box, Diagram, Word\n",
    "from discopy.rigid import Cup, Cap, Functor, Swap\n",
    "from discopy.quantum.circuit import bit, qubit\n",
    "from discopy.quantum import Measure\n",
    "from discopy.quantum.tk import to_tk\n",
    "from discopy.quantum.tk import Circuit as tk_Circuit_inDCP\n",
    "\n",
    "from pytket import Circuit as tk_Circuit\n",
    "\n",
    "#-----------------------------\n",
    "# atomic pregroup grammar types\n",
    "#-----------------------------\n",
    "s, n = Ty('S'), Ty('N')\n",
    "\n",
    "#----------------------------------------\n",
    "# settings concerning the ansaetze\n",
    "#----------------------------------------\n",
    "q_s = 0        # number of qubits for sentence type s\n",
    "q_n = 1        # number of qubits for noun type n\n",
    "depth = 2      # number of IQP layers for non-single-qubit words\n",
    "p_n = 1        # number of parameters for a single-qubit word (noun); valued in {1,2,3}.\n",
    "\n",
    "#----------------------------------------\n",
    "# Parameters concerning the optimisation\n",
    "#----------------------------------------\n",
    "n_runs = 20       # number of runs over training procedure\n",
    "niter  = 2000     # number of iterations for any optimisation run of training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018ba709",
   "metadata": {},
   "outputs": [],
   "source": [
    "#******************************************\n",
    "# Data import\n",
    "#******************************************\n",
    "\n",
    "# import train and test datasets: the data entries are all strings of the form 'label sentence' \n",
    "# with the label in {0,1} and with the sentence of the form \"word1_POStag1 word2_POStag2 ...\"\n",
    "\n",
    "with open('../datasets/rp_train_data.txt') as f:\n",
    "    training_data_raw = f.readlines()\n",
    "\n",
    "with open('../datasets/rp_test_data.txt') as f:\n",
    "    testing_data_raw = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd75b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#***************************************************************\n",
    "# Turn the raw input data into data structures convenient below\n",
    "#***************************************************************\n",
    "\n",
    "vocab_dict = dict()     # dictionary to be filled with the vocabulary in the form { word : POStag }\n",
    "data = dict()           # dictionary to be filled with all the data (from train and test subsets); entries of the \n",
    "                        # form { sentence : label } with label encoding '1' as [1.0, 0.0] and '0' as [0.0, 1.0].\n",
    "training_data = []      # list of sentences in the train dataset as strings \"word1 word2 ...\"\n",
    "testing_data = []       # list of sentences in the test dataset as strings \"word1 word2 ...\"\n",
    "\n",
    "# Go through the train data\n",
    "for sent in training_data_raw:\n",
    "    words = sent[2:].split() \n",
    "    sent_untagged = ''\n",
    "    for word in words:\n",
    "        word_untagged, tag = word.split('_')\n",
    "        vocab_dict[word_untagged] = tag\n",
    "        sent_untagged += word_untagged + ' '\n",
    "    sentence = sent_untagged[:-1]\n",
    "    training_data.append(sentence)\n",
    "    label = [1.0, 0.0] if sent[0] == '1' else [0.0, 1.0]\n",
    "    data[sentence] = label\n",
    "\n",
    "# Go through the test data\n",
    "for sent in testing_data_raw:\n",
    "    words = sent[2:].split() \n",
    "    sent_untagged = ''\n",
    "    for word in words:\n",
    "        word_untagged, tag = word.split('_')\n",
    "        vocab_dict[word_untagged] = tag\n",
    "        sent_untagged += word_untagged + ' '\n",
    "    sentence = sent_untagged[:-1]\n",
    "    testing_data.append(sentence)\n",
    "    label = [1.0, 0.0] if sent[0] == '1' else [0.0, 1.0]\n",
    "    data[sentence] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2f186d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#******************************************\n",
    "# Pregroup grammar level\n",
    "#******************************************\n",
    "\n",
    "# The needed composite types of words\n",
    "tv = n.r @ s @ n.l                          # type of transitive verbs\n",
    "that_subj_type = n.r @ n @ s.l @ n          # type of a relative pronoun as a subject\n",
    "that_obj_type = n.r @ n @ (n.l).l @ s.l     # type of a relative pronoun as an object\n",
    "\n",
    "# The two needed pregroup grammar wirings \n",
    "#---------------------------------\n",
    "grammar_subj = (Cup(n, n.r) @ Id(n) @ Id(s.l) @ Cup(n, n.r) @ Id(s) @ Cup(n.l, n)) >> (Id(n) @ Cup(s.l, s))\n",
    "grammar_obj = (Cup(n, n.r) @ Id(n @ (n.l).l @ s.l) @ Cup(n, n.r) @ Id(s @ n.l)) >> (Id(n @ (n.l).l) @ Cup(s.l, s) @ Id(n.l)) >> (Id(n) @ Cup((n.l).l, n.l))\n",
    "\n",
    "# The pregroup vocabulary \n",
    "#------------------------\n",
    "# (note we need the noun effects with type n.l as well as n.r) \n",
    "vocab_dict_pg = dict()\n",
    "vocab_dict_pg_psr = dict()\n",
    "vocab_dict_pg_psr_nl = dict()\n",
    "for word in vocab_dict:\n",
    "    if vocab_dict[word] == 'N':\n",
    "        vocab_dict_pg.update({word: Word(word, n)})\n",
    "        vocab_dict_pg_psr.update({word: Box(word, n.r, Ty())})\n",
    "        vocab_dict_pg_psr_nl.update({word: Box(word, n.l, Ty())})\n",
    "    if vocab_dict[word] == 'V':\n",
    "        vocab_dict_pg.update({word: Word(word, tv)})\n",
    "        vocab_dict_pg_psr.update({word: Word(word, tv)})\n",
    "vocab = list(vocab_dict_pg.values())\n",
    "vocab_psr = list(vocab_dict_pg_psr.values())\n",
    "\n",
    "# The corresponding two kinds of 'that'\n",
    "that_subj = Word('that', that_subj_type)\n",
    "that_obj = Word('that', that_obj_type)\n",
    "        \n",
    "# Go through data and create the diagrams for all phrases and fill into data_pg, \n",
    "# while filling data_pg_psr with the phrases where the nouns have been 'bent around'.\n",
    "data_pg = dict()\n",
    "data_pg_psr = dict()\n",
    "for sentstr in data:\n",
    "    word_list = sentstr.split()\n",
    "    if data[sentstr] == [0.0, 1.0]:   # subject case\n",
    "        sent = (vocab_dict_pg[word_list[0]] @ that_subj @ vocab_dict_pg[word_list[2]] @ vocab_dict_pg[word_list[3]]) >> grammar_subj\n",
    "        sent_psr = (Cap(n.r, n) @ Cap(n, n.l)) >> (vocab_dict_pg_psr[word_list[0]] @ Id(n) @ that_subj @ vocab_dict_pg[word_list[2]] @ Id(n) @ vocab_dict_pg_psr_nl[word_list[3]]) >> grammar_subj\n",
    "    if data[sentstr] == [1.0, 0.0]:   # object case\n",
    "        sent = (vocab_dict_pg[word_list[0]] @ that_obj @ vocab_dict_pg[word_list[2]] @ vocab_dict_pg[word_list[3]]) >> grammar_obj\n",
    "        sent_psr = (Cap(n.r, n) @ Cap(n.r, n)) >> (vocab_dict_pg_psr[word_list[0]] @ Id(n) @ that_obj @ vocab_dict_pg_psr[word_list[2]] @ Id(n) @ vocab_dict_pg[word_list[3]]) >> grammar_obj\n",
    "    data_pg.update({sentstr: sent})\n",
    "    data_pg_psr.update({sentstr: sent_psr.normal_form()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9a7b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#************************************************************************\n",
    "# Two example sentences to see the two different cases diagrammatically:\n",
    "#************************************************************************\n",
    "\n",
    "print('----------------------------------------------')\n",
    "print('Ordinary DisCoCat diagrams')\n",
    "print('----------------------------------------------')\n",
    "print('This is the subject case ([0.0, 1.0]):')\n",
    "data_pg['organization that establish church'].draw()\n",
    "print('This is the object case ([1.0, 0.0]):')\n",
    "data_pg['organization that church establish'].draw()\n",
    "print('----------------------------------------------')\n",
    "print('The DisCoCat diagrams with nouns bent around')\n",
    "print('----------------------------------------------')\n",
    "print('This is the subject case ([0.0, 1.0]):')\n",
    "data_pg_psr['organization that establish church'].draw()\n",
    "print('This is the object case ([1.0, 0.0]):')\n",
    "data_pg_psr['organization that church establish'].draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78dca105",
   "metadata": {},
   "outputs": [],
   "source": [
    "#*****************************************************\n",
    "# Translation to quantum circuits\n",
    "#*****************************************************\n",
    "from discopy.quantum import Ket, IQPansatz, Bra\n",
    "from discopy.quantum.gates import sqrt, H, CZ, Rz, Rx, CX\n",
    "from discopy.quantum.circuit import Id\n",
    "from discopy import CircuitFunctor\n",
    "from discopy.quantum.circuit import Circuit as DCP_Circuit\n",
    "\n",
    "\n",
    "ob = {s: q_s, n: q_n}                           # assignment of number of qubits to atomic grammatical types\n",
    "ob_cqmap = {s: qubit ** q_s, n: qubit ** q_n}   # the form in which it is needed for discopy's cqmap module\n",
    "\n",
    "#-----------------------------------------\n",
    "# parametrised part of ansaetze\n",
    "#-----------------------------------------\n",
    "\n",
    "def single_qubit_iqp_ansatz(params):\n",
    "    if len(params) == 1:\n",
    "        return Rx(params[0])  \n",
    "    if len(params) == 2:\n",
    "        return Rx(params[0]) >> Rz(params[1])\n",
    "    if len(params) == 3:\n",
    "        return IQPansatz(1, params)       \n",
    "\n",
    "def ansatz_state(state, params):  \n",
    "    arity = sum(ob[Ty(factor.name)] for factor in state.cod)\n",
    "    if arity == 1:\n",
    "        return Ket(0) >> single_qubit_iqp_ansatz(params)\n",
    "    else:\n",
    "        return Ket(*tuple([0 for i in range(arity)])) >> IQPansatz(arity, params)\n",
    "    \n",
    "def ansatz_effect(effect, params):  \n",
    "    arity = sum(ob[Ty(factor.name)] for factor in effect.dom)\n",
    "    if arity == 1:\n",
    "        return single_qubit_iqp_ansatz(params) >> Bra(0)\n",
    "    else:\n",
    "        return IQPansatz(arity, params) >> Bra(*tuple([0 for i in range(arity)]))\n",
    "       \n",
    "def ansatz(box, params):\n",
    "    dom_type = box.dom\n",
    "    cod_type = box.cod\n",
    "    if len(dom_type) == 0 and len(cod_type) != 0:\n",
    "        return ansatz_state(box, params)\n",
    "    if len(dom_type) != 0 and len(cod_type) == 0:\n",
    "        return ansatz_effect(box, params)\n",
    "\n",
    "#-----------------------------------------\n",
    "# unparametrised part of ansaetze\n",
    "#-----------------------------------------\n",
    "\n",
    "def relpron_ansatz(s_o_case):                     # relpron modelled as a frobenius spider in a state\n",
    "    GHZ = Ket(0, 0, 0) >> H @ H @ H >> CZ @ Id(1) >> Id(1) @ CZ >> H @ Id(1) @ H\n",
    "    plus_state = Ket(*[0 for i in range(ob[s])])  # on s type wire\n",
    "    if ob[s] != 0:                                # for 1-dim space (0 qubits) there is only one normalised states.\n",
    "        gate = H\n",
    "        for i in range(1, ob[s]): \n",
    "            gate = gate @ H    \n",
    "        plus_state = plus_state >> gate\n",
    "    circ = GHZ\n",
    "    for i in range(1, ob[n]):\n",
    "        circ = circ @ GHZ\n",
    "    circ = circ >> DCP_Circuit.permutation([x + 3*y for x in range(3) for y in range(ob[n])])\n",
    "    if s_o_case == 'subj':\n",
    "        return circ >> Id(ob_cqmap[n] @ ob_cqmap[n]) @ plus_state @ Id(ob_cqmap[n])\n",
    "    if s_o_case == 'obj':\n",
    "        return circ @ plus_state\n",
    "    \n",
    "#----------------------------------------------------------\n",
    "# Define parametrised functor to quantum circuits\n",
    "#----------------------------------------------------------\n",
    "\n",
    "def F(params): \n",
    "    ar = dict()\n",
    "    # parametrised morphisms\n",
    "    for i in range(len(vocab_psr)):\n",
    "        pgbox = vocab_psr[i]\n",
    "        qbox = ansatz(vocab_psr[i], params[i])\n",
    "        ar.update({pgbox: qbox})\n",
    "        if pgbox.cod == Ty():\n",
    "            ar.update({Box(pgbox.name, n.l, Ty()): qbox})\n",
    "    # unparametrised morphisms\n",
    "    ar.update({that_subj: relpron_ansatz('subj'), that_obj: relpron_ansatz('obj')})\n",
    "    return CircuitFunctor(ob_cqmap, ar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f439b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#*****************************************************\n",
    "# The functions to deal with the parametrisation\n",
    "#*****************************************************\n",
    "\n",
    "def param_shapes(vocab_psr):\n",
    "    parshapes = []    \n",
    "    for box in vocab_psr:\n",
    "        dom_type = box.dom\n",
    "        cod_type = box.cod\n",
    "        dom_arity = sum(ob[Ty(factor.name)] for factor in box.dom)\n",
    "        cod_arity = sum(ob[Ty(factor.name)] for factor in box.cod)\n",
    "        if dom_arity == 0 or cod_arity == 0:  # states and effects\n",
    "            arity = max(dom_arity, cod_arity)\n",
    "            assert arity != 0\n",
    "            if arity == 1:\n",
    "                parshapes.append((p_n,))       \n",
    "            if arity != 1:\n",
    "                parshapes.append((depth, arity-1))\n",
    "    return parshapes\n",
    "\n",
    "def rand_params(par_shapes):\n",
    "    params = np.array([]) \n",
    "    for i in range(len(par_shapes)):\n",
    "         params = np.concatenate((params, np.ravel(np.random.rand(*par_shapes[i]))))\n",
    "    return params \n",
    "\n",
    "def reshape_params(unshaped_pars, par_shapes):\n",
    "    pars_reshaped = [[] for ii in range(len(par_shapes))]\n",
    "    shift = 0\n",
    "    for ss, s in enumerate(par_shapes):\n",
    "        idx0 = 0 + shift\n",
    "        if len(s) == 1:\n",
    "            idx1 = s[0] + shift\n",
    "        elif len(s) == 2:\n",
    "            idx1 = s[0] * s[1] + shift\n",
    "        pars_reshaped[ss] = np.reshape(unshaped_pars[idx0:idx1], s)\n",
    "        if len(s) == 1:\n",
    "            shift += s[0]\n",
    "        elif len(s) == 2:\n",
    "            shift += s[0] * s[1]\n",
    "    return pars_reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4f8555",
   "metadata": {},
   "outputs": [],
   "source": [
    "#****************************************\n",
    "# The parameters of the current model\n",
    "#****************************************\n",
    "\n",
    "par_shapes = param_shapes(vocab_psr)\n",
    "rand_unshaped_pars = rand_params(par_shapes)\n",
    "rand_shaped_pars = reshape_params(rand_unshaped_pars, par_shapes)\n",
    "\n",
    "print('Number of parameters:    ', len(rand_unshaped_pars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9288260d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#**************************************************************\n",
    "# Quantum circuit diagrams for 'that' ansaetze and example sentences \n",
    "#**************************************************************\n",
    "\n",
    "func = F(rand_shaped_pars)\n",
    "\n",
    "print(\"The ansatz for 'that' in subject case:\")\n",
    "relpron_ansatz('subj').draw()\n",
    "\n",
    "print(\"The ansatz for 'that' in object case:\")\n",
    "relpron_ansatz('obj').draw()\n",
    "\n",
    "print('Example diagram from above for the subject case mapped under F:')\n",
    "func(data_pg_psr['organization that establish church']).draw(draw_box_labels=True, figsize=(7, 7), nodesize = 0.4)\n",
    "\n",
    "print('Example diagram from above for the object case mapped under F:')\n",
    "func(data_pg_psr['organization that church establish']).draw(draw_box_labels=True, figsize=(7, 7), nodesize = 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34956fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#********************************************************************************************\n",
    "# Encode data such that the circuits (for one call of cost function etc.) can be sent as one\n",
    "# job to quantum hardware.\n",
    "#********************************************************************************************\n",
    "\n",
    "train_labels = []\n",
    "train_circuits_pg_psr = []\n",
    "for sentstr in training_data:\n",
    "    train_circuits_pg_psr.append(data_pg_psr[sentstr])\n",
    "    train_labels.append(np.array(data[sentstr]))\n",
    "train_labels = np.array(train_labels)\n",
    "\n",
    "test_labels = []\n",
    "test_circuits_pg_psr = []\n",
    "for sentstr in testing_data:\n",
    "    test_circuits_pg_psr.append(data_pg_psr[sentstr])\n",
    "    test_labels.append(np.array(data[sentstr]))\n",
    "test_labels = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7c1b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#**********************************************************************************************************\n",
    "# The cost function for optimisation and the error functions \n",
    "#**********************************************************************************************************\n",
    "from jax import numpy as jnp\n",
    "from jax import jit\n",
    "\n",
    "def get_cost(unshaped_params):\n",
    "    func = F(reshape_params(unshaped_params, par_shapes))\n",
    "    train_circuits = [func(circ) for circ in train_circuits_pg_psr]\n",
    "    results = DCP_Circuit.eval(*train_circuits)\n",
    "    results_tweaked = [jnp.abs(jnp.array(res.array) - 1e-9) for res in results]\n",
    "    pred_labels_distrs = [res / jnp.sum(res) for res in results_tweaked]\n",
    "    cross_entropies = jnp.array([jnp.sum(train_labels[s] * jnp.log2(pred_labels_distrs[s])) for s in range(len(train_labels))])\n",
    "    return -1 / len(training_data) * jnp.sum(cross_entropies)\n",
    "\n",
    "def get_train_error(unshaped_params):\n",
    "    func = F(reshape_params(unshaped_params, par_shapes))\n",
    "    train_circuits = [func(circ) for circ in train_circuits_pg_psr]\n",
    "    results = DCP_Circuit.eval(*train_circuits)\n",
    "    results_tweaked = [jnp.abs(jnp.array(res.array) - 1e-9) for res in results]\n",
    "    pred_labels_distrs = [res / jnp.sum(res) for res in results_tweaked]\n",
    "    assert len(pred_labels_distrs[0]) == 2  # rounding only makes sense if labels are binary tuples\n",
    "    pred_labels = [jnp.round(res) for res in pred_labels_distrs]\n",
    "    error = 0.0\n",
    "    for i in range(len(pred_labels)):\n",
    "        diff = jnp.sum(jnp.abs(train_labels[i] - pred_labels[i]))\n",
    "        error += jnp.min(jnp.array([diff, 1.0]))\n",
    "    return error * 100 / len(training_data)\n",
    "\n",
    "def get_test_error(unshaped_params):\n",
    "    func = F(reshape_params(unshaped_params, par_shapes))\n",
    "    test_circuits = [func(circ) for circ in test_circuits_pg_psr]\n",
    "    results = DCP_Circuit.eval(*test_circuits)\n",
    "    results_tweaked = [jnp.abs(jnp.array(res.array) - 1e-9) for res in results]\n",
    "    pred_labels_distrs = [res / jnp.sum(res) for res in results_tweaked]\n",
    "    assert len(pred_labels_distrs[0]) == 2  # rounding only makes sense if labels are binary tuples\n",
    "    pred_labels = [jnp.round(res) for res in pred_labels_distrs]\n",
    "    error = 0.0\n",
    "    for i in range(len(pred_labels)):\n",
    "        diff = jnp.sum(jnp.abs(test_labels[i] - pred_labels[i]))\n",
    "        error += jnp.min(jnp.array([diff, 1.0]))\n",
    "    return error * 100 / len(testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cc2d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#*************************************************************************************************\n",
    "# Define the jitted versions of above three functions. Then one by one do a \n",
    "# loop over two calls to let jit do its thing so that function call is fast when doing optimisation.\n",
    "#*************************************************************************************************\n",
    "\n",
    "get_cost_jit = jit(get_cost)\n",
    "get_train_error_jit = jit(get_train_error)\n",
    "get_test_error_jit = jit(get_test_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2767339e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    rand_unshaped_pars = rand_params(par_shapes)\n",
    "    print('-------------')\n",
    "    start = time()\n",
    "    print('Cost: ', get_cost_jit(rand_unshaped_pars))\n",
    "    print('Time taken for this iteration: ', time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a182a6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    rand_unshaped_pars = rand_params(par_shapes)\n",
    "    print('-------------')\n",
    "    start = time()\n",
    "    print('Train Error: ', get_train_error_jit(rand_unshaped_pars))\n",
    "    print('Time taken for this iteration: ', time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84323f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    rand_unshaped_pars = rand_params(par_shapes)\n",
    "    print('-------------')\n",
    "    start = time()\n",
    "    print('Test Error : ', get_test_error_jit(rand_unshaped_pars))\n",
    "    print('Time taken for this iteration: ', time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693d6df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#**********************************************************************************\n",
    "# Minimization algorithm\n",
    "#**********************************************************************************\n",
    "\n",
    "# This is building on the minimizeSPSA function from the noisyopt package (https://github.com/andim/noisyopt);\n",
    "# here only adjusted for our purposes (mostly with quantum implementations in mind)\n",
    "\n",
    "def my_spsa(get_cost, get_train_error, x0,\n",
    "            bounds=None, niter=100, a=1.0, c=1.0, alpha=0.602, gamma=0.101,\n",
    "            print_iter=False, filename='spsa_output'):\n",
    "    A = 0.01 * niter\n",
    "    N = len(x0)\n",
    "    if bounds is None:\n",
    "        project = lambda x: x\n",
    "    else:\n",
    "        bounds = np.asarray(bounds)\n",
    "        project = lambda x: np.clip(x, bounds[:, 0], bounds[:, 1])    \n",
    "    param_history = []\n",
    "    func_history = []\n",
    "    error_history = []\n",
    "    x = x0    \n",
    "    \n",
    "    # Loop over iterations\n",
    "    for k in range(niter):\n",
    "        if print_iter:\n",
    "            print('-------------', '\\n', 'iteration: ', k, sep='')\n",
    "        start = time()\n",
    "        \n",
    "        # determine stepping parameters\n",
    "        ak = a/(k+1.0+A)**alpha\n",
    "        ck = c/(k+1.0)**gamma\n",
    "        delta = np.random.choice([-1, 1], size=N)\n",
    "        \n",
    "        # move in + direction from previous x\n",
    "        xplus = project(x + ck*delta)        \n",
    "        if print_iter:\n",
    "            print('Call for xplus')\n",
    "        funcplus = get_cost(xplus)\n",
    "        \n",
    "        # move in - direction from previous x\n",
    "        xminus = project(x - ck * delta)\n",
    "        if print_iter:\n",
    "            print('Call for xminus')\n",
    "        funcminus = get_cost(xminus)\n",
    "        \n",
    "        # new step\n",
    "        grad = (funcplus - funcminus) / (xplus-xminus)\n",
    "        x = project(x - ak*grad)\n",
    "        param_history.append(x)\n",
    "        \n",
    "        # determine current func and error\n",
    "        current_func_value = get_cost(x)\n",
    "        error = get_train_error(x)\n",
    "        func_history.append(current_func_value)\n",
    "        error_history.append(error)\n",
    "\n",
    "        # save to file\n",
    "        dump_data = {\n",
    "            'param_history': param_history,\n",
    "            'func_history': func_history,\n",
    "            'error_history': error_history\n",
    "        }\n",
    "        with open(filename+'.pickle', 'wb') as file_handle:\n",
    "            pickle.dump(dump_data, file_handle)\n",
    "        \n",
    "        if print_iter:\n",
    "            print('Time taken for this iteration: ', time() - start)\n",
    "    return param_history, func_history, error_history "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d114d175",
   "metadata": {},
   "outputs": [],
   "source": [
    "#*****************************************************\n",
    "# Optimisation settings\n",
    "#*****************************************************\n",
    "\n",
    "bounds = [[0.0, 1.0] for ii in range(len(rand_unshaped_pars))]\n",
    "\n",
    "c_fix = 0.1 \n",
    "#leave alpha and gamma as the default (which is as recommended), i.e. alpha = 0.602 and gamma = 0.101\n",
    "\n",
    "#-----------------------------------\n",
    "# calculate well-educated guess for parameter 'a'. \n",
    "# (below calcucation follows the heuristics from: \n",
    "#  https://www.jhuapl.edu/SPSA/PDF-SPSA/Spall_Implementation_of_the_Simultaneous.PDF )\n",
    "#-----------------------------------\n",
    "\n",
    "desired_param_change = 0.005  # rough change of a parameter in early iterations.\n",
    "\n",
    "alpha = 0.602     \n",
    "A = niter*0.01    \n",
    "c_0 = c_fix\n",
    "\n",
    "a_est = 0.0\n",
    "nruns = 1000\n",
    "for l in range(nruns):\n",
    "    rand_unshaped_pars = rand_params(par_shapes)\n",
    "    delta_0 = np.array([np.random.randint(0,2) for i in range(len(rand_unshaped_pars))])*2\\\n",
    "              - np.array([1 for i in range(len(rand_unshaped_pars))])\n",
    "    g0_estimate = (get_cost_jit(rand_unshaped_pars + c_0*delta_0) - get_cost_jit(rand_unshaped_pars - c_0*delta_0))/(2*c_0)\n",
    "    a_est += np.abs(desired_param_change * ((A +1)**alpha) / g0_estimate )\n",
    "a_est = a_est/nruns\n",
    "print('Calculated good choice for a=', a_est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed0009d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#**********************************************************\n",
    "# Training the model\n",
    "#**********************************************************\n",
    "param_histories = []\n",
    "cost_histories = np.zeros((n_runs, niter))\n",
    "error_train_histories = np.zeros((n_runs, niter))\n",
    "\n",
    "for i in range(n_runs):\n",
    "    print('---------------------------------')\n",
    "    print('Start run ', i+1)\n",
    "    rand_unshaped_pars = rand_params(par_shapes)\n",
    "    start = time()\n",
    "    res = my_spsa(get_cost_jit, get_train_error_jit, rand_unshaped_pars,\n",
    "                  bounds=bounds, niter=niter, a=a_est, c=c_fix,\n",
    "                  print_iter=False, filename=('RP_task_SPSAOutput_ECS_Run' + str(i)))\n",
    "    param_histories.append(res[0])   \n",
    "    cost_histories[i, :] = res[1]\n",
    "    error_train_histories[i, :] = res[2]    \n",
    "    print('run', i+1, 'done')\n",
    "    print('Time taken: ', round(time() - start,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0b9379",
   "metadata": {},
   "outputs": [],
   "source": [
    "#************************************\n",
    "# Calculate test errors\n",
    "#************************************\n",
    "error_test_histories = np.zeros((n_runs,niter))\n",
    "\n",
    "for i in range(n_runs):\n",
    "    test_errors = []\n",
    "    for params in param_histories[i]:\n",
    "        test_errors.append(get_test_error_jit(params))\n",
    "    error_test_histories[i,:] = test_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06647b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#************************************\n",
    "# Calculate average cost and errors\n",
    "#************************************\n",
    "\n",
    "cost_history_mean = np.zeros(niter)\n",
    "error_train_history_mean = np.zeros(niter)\n",
    "error_test_history_mean = np.zeros(niter)\n",
    "\n",
    "for i in range(niter):\n",
    "    cost_history_mean[i] = np.mean(cost_histories[:,i])\n",
    "    error_train_history_mean[i] = np.mean(error_train_histories[:,i]) \n",
    "    error_test_history_mean[i] = np.mean(error_test_histories[:,i]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67b7611",
   "metadata": {},
   "outputs": [],
   "source": [
    "#****************************************************\n",
    "# Summary plot\n",
    "#****************************************************\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(13, 8))\n",
    "\n",
    "ax1.plot(range(len(cost_history_mean)), cost_history_mean, '-k', markersize=4, label='cost')\n",
    "ax1.set_ylabel(r\"Cost\", fontsize='x-large')\n",
    "ax1.set_xlabel(r\"SPSA~iterations\", fontsize='x-large')\n",
    "ax1.legend(loc='upper center', fontsize='x-large')\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.set_ylabel(r\"Error in \\%\", fontsize='x-large')\n",
    "ax2.plot(range(len(error_train_history_mean)), error_train_history_mean, '-g', markersize=4, label='train error')\n",
    "ax2.plot(range(len(error_test_history_mean)), error_test_history_mean, '-b', markersize=4, label='test error')\n",
    "ax2.legend(loc='upper right', fontsize='x-large')\n",
    "\n",
    "\n",
    "plt.title('RP task, classical simulation -- results', fontsize='x-large')\n",
    "plt.savefig('RP_task_ECS_Results.png', dpi=300, facecolor='white')  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc764e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
